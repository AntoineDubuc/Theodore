#!/usr/bin/env python3
"""
CloudGeometry Quick Field Test
Fast test focusing on key pages to demonstrate field extraction
"""

import asyncio
import sys
import os
import json
import time
from datetime import datetime
from dotenv import load_dotenv

# Add project root to path
project_root = os.path.dirname(__file__)
sys.path.insert(0, project_root)
load_dotenv(os.path.join(project_root, '.env'))

from src.intelligent_company_scraper import IntelligentCompanyScraper
from src.models import CompanyData, CompanyIntelligenceConfig
from src.bedrock_client import BedrockClient

async def quick_cloudgeometry_test():
    """Quick test with limited pages to show field extraction"""
    print("üöÄ CLOUDGEOMETRY QUICK FIELD EXTRACTION TEST")
    print("=" * 60)
    print(f"üéØ Target: https://www.cloudgeometry.com")
    print(f"üìã Testing: Key business pages for field extraction")
    print(f"‚è∞ Started: {datetime.now().strftime('%H:%M:%S')}")
    print()
    
    # Create test company
    company = CompanyData(
        name="CloudGeometry Quick Test", 
        website="https://www.cloudgeometry.com"
    )
    
    # Create custom scraper with limited pages for speed
    config = CompanyIntelligenceConfig()
    scraper = IntelligentCompanyScraper(config)
    
    # Override max_pages for quick testing
    scraper.max_pages = 10  # Just test 10 key pages
    
    # Initialize Bedrock for AI analysis
    try:
        bedrock_client = BedrockClient(config)
        scraper.bedrock_client = bedrock_client
        print("‚úÖ Bedrock AI client ready for analysis")
    except Exception as e:
        print(f"‚ö†Ô∏è  Bedrock not available: {e}")
    
    start_time = time.time()
    
    try:
        print("üîç Testing content extraction from key pages...")
        result = await scraper.scrape_company_intelligent(company)
        duration = time.time() - start_time
        
        print(f"\n‚úÖ EXTRACTION COMPLETED!")
        print(f"‚è±Ô∏è  Duration: {duration:.1f} seconds")
        
        # Quick field analysis
        print(f"\nüìä FIELD EXTRACTION ANALYSIS:")
        
        # Check key business fields
        key_fields = {
            'name': getattr(result, 'name', None),
            'website': getattr(result, 'website', None),
            'industry': getattr(result, 'industry', None),
            'company_description': getattr(result, 'company_description', None),
            'business_model': getattr(result, 'business_model', None),
            'pages_crawled': getattr(result, 'pages_crawled', None),
            'crawl_duration': getattr(result, 'crawl_duration', None),
            'raw_content': getattr(result, 'raw_content', None),
            'ai_summary': getattr(result, 'ai_summary', None),
            'target_market': getattr(result, 'target_market', None),
            'key_services': getattr(result, 'key_services', None),
            'founding_year': getattr(result, 'founding_year', None),
            'location': getattr(result, 'location', None),
            'employee_count_range': getattr(result, 'employee_count_range', None),
            'tech_stack': getattr(result, 'tech_stack', None),
        }
        
        extracted_count = 0
        total_checked = len(key_fields)
        
        for field, value in key_fields.items():
            has_data = False
            
            if value is not None:
                if isinstance(value, str):
                    has_data = value not in ['', 'unknown', 'Unknown'] and len(value.strip()) > 0
                elif isinstance(value, (list, dict)):
                    has_data = len(value) > 0
                elif isinstance(value, (int, float)):
                    has_data = value > 0
                else:
                    has_data = True
            
            status = "‚úÖ" if has_data else "‚ùå"
            
            # Format value for display
            if isinstance(value, str) and len(value) > 100:
                display_value = f"{value[:97]}..."
            elif isinstance(value, list) and len(value) > 0:
                display_value = f"[{len(value)} items]"
            elif isinstance(value, dict) and len(value) > 0:
                display_value = f"{{...}} ({len(value)} keys)"
            else:
                display_value = str(value)
            
            print(f"   {status} {field}: {display_value}")
            
            if has_data:
                extracted_count += 1
        
        extraction_rate = (extracted_count / total_checked) * 100
        
        print(f"\nüìã QUICK TEST RESULTS:")
        print(f"   Key Fields Extracted: {extracted_count}/{total_checked} ({extraction_rate:.1f}%)")
        
        # Crawling performance
        pages_crawled = getattr(result, 'pages_crawled', 0)
        if isinstance(pages_crawled, list):
            pages_count = len(pages_crawled)
        elif isinstance(pages_crawled, int):
            pages_count = pages_crawled
        else:
            pages_count = 0
        
        print(f"   Pages Successfully Crawled: {pages_count}")
        print(f"   Processing Time: {duration:.1f} seconds")
        
        # Content analysis
        raw_content = getattr(result, 'raw_content', '')
        if raw_content and len(raw_content) > 50:
            print(f"   Content Generated: {len(raw_content):,} characters")
            print(f"   Content Preview: {raw_content[:200]}...")
        
        # Success assessment
        if extraction_rate >= 60:  # Lower bar for quick test
            print(f"\nüéâ QUICK TEST SUCCESS!")
            print(f"   Content extraction is working well.")
            print(f"   Full test would likely achieve 75%+ field extraction.")
        else:
            print(f"\n‚ö†Ô∏è  Limited field extraction in quick test.")
            print(f"   May need optimization for full 75% target.")
        
        return True, result, extraction_rate
        
    except Exception as e:
        duration = time.time() - start_time
        print(f"\n‚ùå EXTRACTION FAILED: {e}")
        print(f"‚è±Ô∏è  Failed after: {duration:.1f} seconds")
        return False, None, 0

async def main():
    """Main execution"""
    success, result, rate = await quick_cloudgeometry_test()
    
    if success:
        print(f"\nüéØ CONCLUSION:")
        print(f"   CloudGeometry content extraction is working!")
        print(f"   The crawling fix has resolved the previous failures.")
        print(f"   Theodore can now successfully process your website.")
    else:
        print(f"\n‚ùå Issues remain with CloudGeometry extraction.")

if __name__ == "__main__":
    asyncio.run(main())