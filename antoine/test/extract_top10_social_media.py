#!/usr/bin/env python3
"""
Extract Social Media Links from Top 10 Companies in Google Sheet
================================================================

This script reads the top 10 companies from the Google Sheet and extracts
their social media links using our validated SocialMediaExtractor.

Usage:
    python extract_top10_social_media.py
"""

import os
import sys
import logging
import requests
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# Add parent directories to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

# Import required modules
from src.sheets_integration.google_sheets_service_client import GoogleSheetsServiceClient
from test_social_media_extraction import SocialMediaExtractor

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_top_10_companies() -> List[Dict[str, Any]]:
    """
    Read the top 10 companies from the Google Sheet
    
    Returns:
        List of company dictionaries with name, website, and row_number
    """
    
    # Google Sheet ID from existing configuration
    spreadsheet_id = "1dD1pw9yJzRPFnZRRKGldCJpc29fGmK0vQ-g5sBG-bZk"
    
    # Service account credentials file
    service_account_file = Path("config/credentials/theodore-service-account.json")
    
    if not service_account_file.exists():
        logger.error(f"Service account file not found: {service_account_file}")
        logger.error("Please ensure the service account JSON file is in the config/credentials/ directory")
        return []
    
    try:
        # Initialize the Google Sheets client
        logger.info("üîß Initializing Google Sheets client...")
        sheets_client = GoogleSheetsServiceClient(service_account_file)
        
        # Validate sheet access
        logger.info("üîç Validating access to the Google Sheet...")
        if not sheets_client.validate_sheet_access(spreadsheet_id):
            logger.error("‚ùå Cannot access the Google Sheet")
            return []
        
        # Read companies from the sheet
        logger.info("üìä Reading companies from the 'Companies' sheet...")
        companies = sheets_client.read_companies_to_process(spreadsheet_id)
        
        if not companies:
            logger.warning("‚ö†Ô∏è  No companies found in the sheet")
            return []
        
        # Return top 10 companies
        top_10 = companies[:10]
        logger.info(f"‚úÖ Successfully retrieved {len(top_10)} companies")
        
        return top_10
        
    except Exception as e:
        logger.error(f"‚ùå Error reading companies from sheet: {e}")
        return []


def extract_social_media_for_companies(companies: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Extract social media links for a list of companies
    
    Args:
        companies: List of company dictionaries
        
    Returns:
        List of company dictionaries with social media data added
    """
    
    extractor = SocialMediaExtractor()
    results = []
    
    print(f"\nüåê Extracting Social Media Links for {len(companies)} Companies")
    print("=" * 70)
    
    for i, company in enumerate(companies, 1):
        company_name = company['name']
        website = company['website']
        
        print(f"\n[{i}/{len(companies)}] Processing: {company_name}")
        print(f"Website: {website}")
        
        # Ensure website has protocol
        if website and not website.startswith(('http://', 'https://')):
            website = f"https://{website}"
        
        company_result = {
            'name': company_name,
            'website': website,
            'row_number': company.get('row_number', i + 1),
            'status': 'pending',
            'social_media_links': {},
            'extraction_time': 0.0,
            'error': None
        }
        
        if not website:
            company_result['status'] = 'failed'
            company_result['error'] = 'No website provided'
            print(f"   ‚ùå Skipped - No website provided")
            results.append(company_result)
            continue
        
        try:
            start_time = datetime.now()
            
            # Fetch homepage HTML with enhanced headers
            response = requests.get(website, timeout=15, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.9',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1'
            })
            
            if response.status_code == 200:
                html_content = response.text
                social_links = extractor.extract_social_media_links(html_content)
                
                extraction_time = (datetime.now() - start_time).total_seconds()
                
                company_result['status'] = 'success'
                company_result['social_media_links'] = social_links
                company_result['extraction_time'] = extraction_time
                
                if social_links:
                    print(f"   ‚úÖ Found {len(social_links)} social media links ({extraction_time:.2f}s):")
                    for platform, url in social_links.items():
                        print(f"      üì± {platform}: {url}")
                else:
                    print(f"   ‚ö†Ô∏è  No social media links found ({extraction_time:.2f}s)")
                    
            else:
                company_result['status'] = 'failed'
                company_result['error'] = f'HTTP {response.status_code}'
                print(f"   ‚ùå Failed to fetch HTML: HTTP {response.status_code}")
                
        except requests.exceptions.RequestException as e:
            company_result['status'] = 'failed'
            company_result['error'] = f'Request failed: {str(e)}'
            print(f"   ‚ùå Request failed: {e}")
        except Exception as e:
            company_result['status'] = 'failed'
            company_result['error'] = f'Extraction failed: {str(e)}'
            print(f"   ‚ùå Extraction failed: {e}")
        
        results.append(company_result)
    
    return results


def generate_markdown_report(results: List[Dict[str, Any]]) -> str:
    """
    Generate a markdown report of the social media extraction results
    
    Args:
        results: List of company results with social media data
        
    Returns:
        Markdown formatted report string
    """
    
    # Calculate statistics
    total_companies = len(results)
    successful_extractions = sum(1 for r in results if r['status'] == 'success')
    total_social_links = sum(len(r['social_media_links']) for r in results)
    avg_extraction_time = sum(r['extraction_time'] for r in results) / total_companies if total_companies > 0 else 0
    
    # Platform statistics
    platform_counts = {}
    for result in results:
        for platform in result['social_media_links'].keys():
            platform_counts[platform] = platform_counts.get(platform, 0) + 1
    
    # Generate markdown
    md_content = f"""# Social Media Links Extraction Report

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Summary Statistics

| Metric | Value |
|--------|-------|
| Total Companies Processed | {total_companies} |
| Successful Extractions | {successful_extractions} ({successful_extractions/total_companies*100:.1f}%) |
| Total Social Media Links Found | {total_social_links} |
| Average Extraction Time | {avg_extraction_time:.2f}s |
| Average Links per Company | {total_social_links/successful_extractions:.1f} |

## Platform Distribution

| Platform | Count | Percentage |
|----------|-------|------------|
"""
    
    # Add platform statistics
    for platform, count in sorted(platform_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / successful_extractions * 100) if successful_extractions > 0 else 0
        md_content += f"| {platform.title()} | {count} | {percentage:.1f}% |\n"
    
    md_content += "\n## Company Results\n\n"
    
    # Add individual company results
    for i, result in enumerate(results, 1):
        status_emoji = "‚úÖ" if result['status'] == 'success' else "‚ùå"
        
        md_content += f"### {i}. {result['name']} {status_emoji}\n\n"
        md_content += f"**Website:** {result['website']}\n"
        md_content += f"**Status:** {result['status']}\n"
        md_content += f"**Extraction Time:** {result['extraction_time']:.2f}s\n"
        
        if result['error']:
            md_content += f"**Error:** {result['error']}\n"
        
        if result['social_media_links']:
            md_content += f"**Social Media Links Found:** {len(result['social_media_links'])}\n\n"
            
            for platform, url in result['social_media_links'].items():
                md_content += f"- **{platform.title()}:** {url}\n"
        else:
            md_content += "**Social Media Links Found:** 0\n"
        
        md_content += "\n---\n\n"
    
    # Add methodology section
    md_content += """## Methodology

This report was generated using the following approach:

1. **Data Source:** Top 10 companies from the Theodore Google Sheet
2. **Extraction Method:** Multi-strategy social media link detection
   - CSS selectors targeting header/footer sections
   - Domain pattern matching for 15+ social media platforms
   - Validation to filter out false positives
3. **Platforms Detected:** Facebook, Twitter, LinkedIn, Instagram, YouTube, GitHub, TikTok, Pinterest, Snapchat, Reddit, Discord, Telegram, WhatsApp
4. **Processing:** Each company website was fetched and parsed for social media links
5. **Validation:** Links were validated against known social media domain patterns

## Technical Details

- **Extraction Engine:** SocialMediaExtractor (validated with 100% test pass rate)
- **HTML Parser:** BeautifulSoup4 with comprehensive CSS selectors
- **Request Timeout:** 15 seconds per website
- **User Agent:** Chrome 91.0.4472.124 (standard web browser)
- **Error Handling:** Graceful degradation for network failures and parsing errors

## Next Steps

This data can be used to:
1. **Integrate social media extraction** into the main Antoine crawler
2. **Enhance company profiles** with social media presence data
3. **Improve lead generation** by providing social media contact points
4. **Validate extraction accuracy** against known company social media profiles

---
*Report generated by Theodore Social Media Extraction System*
"""
    
    return md_content


def main():
    """Main execution function"""
    
    print("üöÄ Social Media Links Extraction for Top 10 Companies")
    print("=" * 60)
    
    # Read top 10 companies from Google Sheet
    companies = get_top_10_companies()
    
    if not companies:
        print("‚ùå No companies found to process")
        return
    
    print(f"üìã Found {len(companies)} companies to process:")
    for i, company in enumerate(companies, 1):
        print(f"   {i}. {company['name']} - {company['website']}")
    
    # Extract social media links
    results = extract_social_media_for_companies(companies)
    
    # Generate markdown report
    print(f"\nüìù Generating markdown report...")
    markdown_report = generate_markdown_report(results)
    
    # Save report to file
    output_file = Path("antoine/test/top10_social_media_report.md")
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(markdown_report)
    
    # Print summary
    successful_extractions = sum(1 for r in results if r['status'] == 'success')
    total_social_links = sum(len(r['social_media_links']) for r in results)
    
    print(f"\nüìä Extraction Complete!")
    print(f"   Total companies processed: {len(results)}")
    print(f"   Successful extractions: {successful_extractions}")
    print(f"   Total social media links found: {total_social_links}")
    print(f"   Report saved to: {output_file}")
    
    # Show top companies with most social links
    top_social_companies = sorted(
        [r for r in results if r['social_media_links']], 
        key=lambda x: len(x['social_media_links']), 
        reverse=True
    )[:3]
    
    if top_social_companies:
        print(f"\nüèÜ Top Companies by Social Media Presence:")
        for i, company in enumerate(top_social_companies, 1):
            print(f"   {i}. {company['name']}: {len(company['social_media_links'])} platforms")
    
    print(f"\n‚úÖ Social media extraction complete! Check {output_file} for full report.")


if __name__ == "__main__":
    main()