#!/usr/bin/env python3
"""
Test Bedrock and Gemini clients directly to prove if they work
"""

import sys
import os
sys.path.append('src')

def test_bedrock_client():
    print("üß™ TESTING BEDROCK CLIENT")
    print("="*50)
    
    try:
        from bedrock_client import BedrockClient
        from models import CompanyIntelligenceConfig
        
        # Test 1: Import and initialize
        print("‚úÖ Successfully imported BedrockClient")
        
        # Test 2: Check configuration
        config = CompanyIntelligenceConfig()
        print(f"‚úÖ Config created: {type(config)}")
        
        # Test 3: Initialize client
        try:
            bedrock_client = BedrockClient(config)
            print("‚úÖ BedrockClient initialized successfully")
        except Exception as e:
            print(f"‚ùå BedrockClient initialization failed: {e}")
            return False
        
        # Test 4: Check environment variables
        aws_key = os.getenv('AWS_ACCESS_KEY_ID')
        aws_secret = os.getenv('AWS_SECRET_ACCESS_KEY')
        print(f"AWS_ACCESS_KEY_ID: {'‚úÖ Present' if aws_key else '‚ùå Missing'}")
        print(f"AWS_SECRET_ACCESS_KEY: {'‚úÖ Present' if aws_secret else '‚ùå Missing'}")
        
        # Test 5: Simple API call
        try:
            test_prompt = "What is 2+2? Answer in one word."
            print(f"üß† Testing with prompt: '{test_prompt}'")
            response = bedrock_client.analyze_content(test_prompt)
            print(f"‚úÖ Bedrock response: '{response}'")
            print(f"‚úÖ Response length: {len(response)} characters")
            return True
        except Exception as e:
            print(f"‚ùå Bedrock API call failed: {e}")
            import traceback
            traceback.print_exc()
            return False
            
    except Exception as e:
        print(f"‚ùå Bedrock test completely failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_gemini_client():
    print("\nüß™ TESTING GEMINI CLIENT")
    print("="*50)
    
    try:
        # Test 1: Check environment variable
        gemini_key = os.getenv('GEMINI_API_KEY')
        print(f"GEMINI_API_KEY: {'‚úÖ Present' if gemini_key else '‚ùå Missing'}")
        
        if not gemini_key:
            print("‚ùå Cannot test Gemini without API key")
            return False
            
        # Test 2: Import Gemini
        try:
            import google.generativeai as genai
            print("‚úÖ Successfully imported google.generativeai")
        except ImportError as e:
            print(f"‚ùå Failed to import google.generativeai: {e}")
            return False
        
        # Test 3: Configure Gemini
        try:
            genai.configure(api_key=gemini_key)
            print("‚úÖ Gemini configured successfully")
        except Exception as e:
            print(f"‚ùå Gemini configuration failed: {e}")
            return False
        
        # Test 4: Initialize model
        try:
            model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')
            print("‚úÖ Gemini model initialized successfully")
        except Exception as e:
            print(f"‚ùå Gemini model initialization failed: {e}")
            return False
        
        # Test 5: Simple API call
        try:
            test_prompt = "What is 2+2? Answer in one word."
            print(f"üß† Testing with prompt: '{test_prompt}'")
            response = model.generate_content(test_prompt)
            print(f"‚úÖ Gemini response: '{response.text}'")
            print(f"‚úÖ Response length: {len(response.text)} characters")
            return True
        except Exception as e:
            print(f"‚ùå Gemini API call failed: {e}")
            import traceback
            traceback.print_exc()
            return False
            
    except Exception as e:
        print(f"‚ùå Gemini test completely failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_intelligent_scraper_llm():
    print("\nüß™ TESTING INTELLIGENT SCRAPER LLM INTEGRATION")
    print("="*60)
    
    try:
        from intelligent_company_scraper import IntelligentCompanyScraper
        from models import CompanyIntelligenceConfig
        
        config = CompanyIntelligenceConfig()
        scraper = IntelligentCompanyScraper(config)
        
        print(f"Bedrock client available: {'‚úÖ YES' if scraper.bedrock_client else '‚ùå NO'}")
        print(f"Gemini client available: {'‚úÖ YES' if scraper.gemini_client else '‚ùå NO'}")
        
        # Test the actual LLM call method
        import asyncio
        
        async def test_llm_call():
            try:
                test_prompt = "What is 2+2? Answer in one word."
                print(f"üß† Testing _call_llm_async with: '{test_prompt}'")
                response = await scraper._call_llm_async(test_prompt)
                print(f"‚úÖ LLM call successful: '{response}'")
                print(f"‚úÖ Response length: {len(response)} characters")
                return True
            except Exception as e:
                print(f"‚ùå LLM call failed: {e}")
                import traceback
                traceback.print_exc()
                return False
        
        return asyncio.run(test_llm_call())
        
    except Exception as e:
        print(f"‚ùå Scraper LLM test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("üî¨ COMPREHENSIVE LLM CLIENT TESTING")
    print("="*60)
    
    bedrock_works = test_bedrock_client()
    gemini_works = test_gemini_client()
    scraper_works = test_intelligent_scraper_llm()
    
    print(f"\nüìä FINAL RESULTS:")
    print(f"Bedrock Client: {'‚úÖ WORKING' if bedrock_works else '‚ùå FAILED'}")
    print(f"Gemini Client: {'‚úÖ WORKING' if gemini_works else '‚ùå FAILED'}")
    print(f"Scraper LLM Integration: {'‚úÖ WORKING' if scraper_works else '‚ùå FAILED'}")
    
    if bedrock_works or gemini_works:
        print(f"\n‚úÖ At least one LLM client is working!")
    else:
        print(f"\n‚ùå NO LLM clients are working!")